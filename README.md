# MechaBot â€” Smart Documentation Assistant (RAG)

An **intelligent bot over your docs**: it ingests Markdown/README/notes from a folder, builds a vector index,
and answers questions **with source citations**. Built for quick demos and internship portfolios.

## âœ¨ Features
- Local vector store using **ChromaDB**
- Embeddings via **Sentence-Transformers** (`all-MiniLM-L6-v2`) â€” runs on CPU
- Streamlit chat UI with chat history
- Sources panel with chunk-level citations
- Pluggable LLM: **OpenAI** via `OPENAI_API_KEY` (optional). If not set, MechaBot returns retrieved chunks only.

## ğŸ§± Project layout
```
MechaBot/
â”œâ”€ app/
â”‚  â””â”€ app.py                 # Streamlit chat UI
â”œâ”€ data/sample_docs/         # Example docs (ingest these first)
â”‚  â”œâ”€ README.md
â”‚  â””â”€ config.md
â”œâ”€ scripts/
â”‚  â””â”€ ingest.py              # Build vector index from a folder
â”œâ”€ eval/qna.json             # Tiny evaluation set (optional)
â”œâ”€ requirements.txt
â””â”€ vectorstore/              # Created by Chroma (after ingest)
```

## ğŸš€ Quickstart
```bash
# 1) Create & activate a virtual env (recommended)
python -m venv .venv && source .venv/bin/activate   # on Windows: .venv\Scripts\activate

# 2) Install deps
pip install -r requirements.txt

# 3) (Optional) Set your LLM key
export OPENAI_API_KEY=sk-...                         # Windows PowerShell: $Env:OPENAI_API_KEY="sk-..."

# 4) Ingest docs (use the sample folder or your own)
python scripts/ingest.py --docs data/sample_docs --persist_dir vectorstore

# 5) Run the chat UI
streamlit run app/app.py
```

Open the local URL Streamlit prints (e.g., http://localhost:8501).

## ğŸ§ª Minimal eval (optional)
```bash
python scripts/ingest.py --docs data/sample_docs --persist_dir vectorstore
# Open the app and ask the questions in eval/qna.json; verify answers & citations.
```

## ğŸ› ï¸ Notes
- You can point `--docs` to any folder. Supported types: `.md`, `.txt`. (You can extend to PDFs.)
- If `OPENAI_API_KEY` is **not** set, the app will show top retrieved chunks as the "answer" (good for offline demos).
- For PDFs, consider `pymupdf` or `pypdf` + text extraction, then add to `ALLOWED_EXTS` in `ingest.py`.

## ğŸ§­ Why this project matches â€œKI-gestÃ¼tzte Softwareentwicklung / Textanalyse / intelligente Botsâ€
- **KI-gestÃ¼tzte Softwareentwicklung**: RAG over engineering docs/README/Runbooks speeds onboarding & dev workflows.
- **Analyse von Textdaten**: ingestion, chunking, embeddings, similarity search, and qualitative eval.
- **Entwicklung intelligenter Bots**: a working assistant with citations and a UI.
